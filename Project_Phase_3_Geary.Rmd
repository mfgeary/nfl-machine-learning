---
title: "Predicting Fantasy Football Points Using Machine Learning Techniques"
author: "Marion Geary"
date: 'May 4, 2022'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r}
library(tidyverse)
library(nflverse)
library(tidymodels)
library(knitr)
library(kableExtra)
load('nfl-project.Rdata')
#save.image('nfl-project.Rdata')
```

```{r, eval = F}
mycores <- parallel::detectCores(logical = FALSE)
library(doMC)
registerDoMC(cores = mycores)

all_data <- all_data %>%
  filter(!is.na(fantasy_points)) %>%
  mutate_if(is.character, as.factor)

# remove repeated stats
all_data <- all_data %>% select(-c(pass_yards, pass_touchdowns, yards, rec_touchdowns, rush_attempts, rush_yards, avg_rush_yards, rush_touchdowns))

all_data <- all_data %>% group_by(gsis_id) %>%
  mutate(
      total_completions = cumsum(completions),
      total_completions = lag(total_completions, default = 0),
      total_attempts = cumsum(attempts),
      total_attempts = lag(total_attempts, default = 0),
      total_passing_yards = cumsum(passing_yards),
      total_passing_yards = lag(total_passing_yards, default = 0),
      total_passing_td = cumsum(passing_tds),
      total_passing_td = lag(passing_tds, default = 0),
      total_interceptions = cumsum(interceptions),
      total_interceptions = lag(interceptions, default = 0),
      total_sack_fumbles_lost = cumsum(sack_fumbles_lost),
      total_sack_fumbles_lost = lag(sack_fumbles_lost, default = 0),
      total_rushing_yards = cumsum(rushing_yards),
      total_rushing_yards = lag(rushing_yards, default = 0),
      total_rushing_tds = cumsum(rushing_tds),
      total_rushing_tds = lag(rushing_tds, default = 0),
      total_rushing_fumbles_lost = cumsum(rushing_fumbles_lost),
      total_rushing_fumbles_lost = lag(rushing_fumbles_lost, default = 0),
      total_receiving_yards = cumsum(receiving_yards),
      total_receiving_yards = lag(receiving_yards, default = 0),
      total_receiving_tds = cumsum(receiving_tds),
      total_receiving_tds = lag(receiving_tds, default = 0),
      total_receiving_fumbles_lost = cumsum(receiving_fumbles_lost),
      total_receiving_fumbles_lost = lag(receiving_fumbles_lost, default = 0),
      total_special_teams_tds = cumsum(special_teams_tds),
      total_special_teams_tds = lag(special_teams_tds, default = 0),
      total_def_ints = cumsum(def_ints),
      total_def_ints = lag(total_def_ints, default = 0),
      total_def_sacks = cumsum(def_sacks),
      total_def_sacks = lag(total_def_sacks, default = 0),
    ) %>%
  ungroup() %>%
  select(-c(completions, attempts, passing_yards, passing_tds, interceptions, 
            sack_fumbles_lost, rushing_yards, rushing_tds, rushing_fumbles_lost, 
            receiving_yards, receiving_tds, receiving_fumbles_lost, 
            special_teams_tds, def_ints, def_sacks)
    )

all_data <- all_data %>%
  group_by(gsis_id) %>%
  mutate(
      sacks = lag(cumsum(sacks), default = 0),
      sack_yards = lag(cumsum(sack_yards), default = 0),
      sack_fumbles = lag(cumsum(sack_fumbles), default = 0),
      passing_air_yards = lag(cumsum(passing_air_yards), default = 0),
      passing_yards_after_catch = lag(cumsum(passing_yards_after_catch), default = 0),
      passing_first_downs = lag(cumsum(passing_first_downs), default = 0),
      passing_epa = lag(passing_epa),
      passing_2pt_conversions = lag(cumsum(passing_2pt_conversions)),
      pacr = lag(pacr),
      dakota = lag(dakota),
      carries = lag(cumsum(carries), default = 0),
      rushing_fumbles = lag(cumsum(rushing_fumbles), default = 0),
      rushing_first_downs = lag(cumsum(rushing_first_downs), default = 0),
      rushing_epa = lag(rushing_epa),
      rushing_2pt_conversions = lag(cumsum(rushing_2pt_conversions)),
      receptions = lag(cumsum(receptions), default = 0),
      targets = lag(cumsum(targets), default = 0),
      receiving_fumbles = lag(cumsum(receiving_fumbles), default = 0),
      receiving_air_yards = lag(cumsum(receiving_air_yards), default = 0),
      receiving_yards_after_catch = lag(cumsum(receiving_yards_after_catch), default = 0),
      receiving_first_downs = lag(cumsum(receiving_first_downs), default = 0),
      receiving_epa = lag(cumsum(receiving_epa)),
      receiving_2pt_conversions = lag(cumsum(receiving_2pt_conversions)),
      racr = lag(racr),
      target_share = lag(target_share),
      air_yards_share = lag(air_yards_share),
      wopr = lag(wopr),
      avg_time_to_throw = lag(avg_time_to_throw),
      avg_completed_air_yards = lag(avg_completed_air_yards, default = 0),
      avg_intended_air_yards = lag(avg_intended_air_yards, default = 0),
      avg_air_yards_differential = lag(avg_air_yards_differential),
      aggressiveness = lag(aggressiveness),
      max_completed_air_distance = lag(max_completed_air_distance, default = 0),
      avg_air_yards_to_sticks = lag(avg_air_yards_to_sticks),
      passer_rating = lag(passer_rating),
      completion_percentage = lag(completion_percentage),
      completion_percentage_above_expectation = lag(completion_percentage_above_expectation),
      avg_air_distance = lag(avg_air_distance),
      max_air_distance = lag(max_air_distance), 
      avg_cushion = lag(avg_cushion),
      avg_separation = lag(avg_separation),
      percent_share_of_intended_air_yards = lag(percent_share_of_intended_air_yards),
      catch_percentage = lag(catch_percentage),
      avg_yac = lag(avg_yac),
      avg_yac_above_expectation = lag(avg_yac_above_expectation),
      efficiency = lag(efficiency),
      percent_attempts_gte_eight_defenders = lag(percent_attempts_gte_eight_defenders),
      avg_time_to_los = lag(avg_time_to_los),
      rush_yards_over_expected = lag(rush_yards_over_expected),
      rush_yards_over_expected_per_att = lag(rush_yards_over_expected_per_att),
      rush_pct_over_expected = lag(rush_pct_over_expected),
      def_targets = lag(cumsum(def_targets)),
      def_completions_allowed = lag(cumsum(def_completions_allowed)),
      def_completion_pct = lag(def_completion_pct),
      def_yards_allowed = lag(cumsum(def_yards_allowed)),
      def_yards_allowed_per_cmp = lag(def_yards_allowed_per_cmp),
      def_yards_allowed_per_tgt = lag(def_yards_allowed_per_tgt),
      def_receiving_td_allowed = lag(cumsum(def_receiving_td_allowed)),
      def_air_yards_completed = lag(cumsum(def_air_yards_completed)),
      def_yards_after_catch = lag(cumsum(def_yards_after_catch)),
      def_times_blitzed = lag(cumsum(def_times_blitzed)),
      def_times_hurried = lag(cumsum(def_times_hurried)),
      def_times_hitqb = lag(cumsum(def_times_hitqb)),
      def_pressures = lag(cumsum(def_pressures)),
      def_tackles_combined = lag(cumsum(def_tackles_combined)),
      def_missed_tackles = lag(cumsum(def_missed_tackles)),
      def_missed_tackle_pct = lag(def_missed_tackle_pct),
      passing_drops = lag(cumsum(passing_drops)),
      passing_drop_pct = lag(passing_drop_pct),
      passing_bad_throws = lag(cumsum(passing_bad_throws)),
      passing_bad_throw_pct = lag(passing_bad_throw_pct),
      times_sacked = lag(cumsum(times_sacked)),
      times_blitzed = lag(cumsum(times_blitzed)),
      times_hurried = lag(cumsum(times_hurried)),
      times_hit = lag(cumsum(times_hit)),
      times_pressured = lag(cumsum(times_pressured)),
      times_pressured_pct = lag(times_pressured_pct),
      rushing_yards_before_contact = lag(cumsum(rushing_yards_before_contact)),
      rushing_yards_before_contact_avg = lag(rushing_yards_before_contact_avg),
      rushing_yards_after_contact = lag(cumsum(rushing_yards_after_contact)),
      rushing_yards_after_contact_avg = lag(rushing_yards_after_contact_avg),
      rushing_broken_tackles = lag(cumsum(rushing_broken_tackles)),
      receiving_broken_tackles = lag(cumsum(receiving_broken_tackles)),
      receiving_drop = lag(cumsum(receiving_drop)),
      receiving_drop_pct = lag(receiving_drop_pct),
      receiving_int = lag(cumsum(receiving_int)),
      receiving_rat = lag(receiving_rat),
      offense_snaps = lag(cumsum(offense_snaps)),
      offense_pct = lag(offense_pct),
      defense_snaps = lag(cumsum(defense_snaps)),
      defense_pct = lag(defense_pct),
      st_snaps = lag(cumsum(st_snaps)),
      st_pct = lag(st_pct)
    ) %>% ungroup()

all_data <- all_data %>%
  mutate(birth_date = as.Date(birth_date)) %>%
  mutate(birth_year = lubridate::year(birth_date))

all_data <- all_data %>%
  select(-c(def_receiving_td_allowed, def_times_hitqb, def_missed_tackles,
            total_def_ints, total_def_sacks, defense_pct, game_id,
            report_secondary_injury, birth_date)) %>%
  mutate_if(is.character, as.factor) %>%
  mutate(
     week = is.factor(week),
     opponent = is.factor(opponent),
     game_type = is.factor(game_type),
     gsis_id = is.factor(gsis_id)
    ) 
```

```{r, eval = F}
set.seed(321)

recipe <- all_data %>% recipe(fantasy_points ~ .) %>%
  update_role(gsis_id, full_name, new_role = "id") %>%
  update_role(headshot_url, new_role = "graphics") %>%
  update_role(fantasy_points_ppr, new_role = "comparison") %>%
  step_corr(all_numeric_predictors(), threshold = 0.9) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_zv(all_predictors()) %>%
  step_nzv(all_predictors())

xgb_model <- boost_tree(
    mtry = tune(),
    trees = tune(),
    min_n = tune(),
    tree_depth = tune(),
    learn_rate = tune(),
    loss_reduction = tune(),
    sample_size = tune(),
    stop_iter = tune()
  ) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

xgb_param <- 
   xgb_model %>% 
   parameters() %>% 
   finalize(x = all_data %>% select(-fantasy_points))

xgb_tuning_grid <- grid_max_entropy(xgb_param, size = 100)

xgb_wkflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(xgb_model)

nfl_folds <- vfold_cv(all_data, v = 5, strata = position)

xgb_tuned <- xgb_wkflow %>%
  tune_grid(grid = xgb_tuning_grid, resamples = nfl_folds)

note<-xgb_tuned[[".metrics"]]

xgb_tune_wkflow <- finalize_workflow(
    xgb_wkflow,
    select_best(xgb_tuned, "rmse")
  )

xgb_cv_fit <- xgb_tune_wkflow %>%
  fit_resamples(resamples = nfl_folds)

xgb_metrics <- collect_metrics(xgb_cv_fit)
```

```{r, eval = F}
svm_recipe <- all_data %>% recipe(fantasy_points ~ .) %>%
  update_role(gsis_id, full_name, new_role = "id") %>%
  update_role(headshot_url, new_role = "graphics") %>%
  update_role(fantasy_points_ppr, new_role = "comparison") %>%
  step_corr(all_numeric_predictors(), threshold = 0.9) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal()) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_nzv(all_predictors())

nfl_folds <- vfold_cv(all_data, v = 2, strata = position)

svm_rbf_model <- svm_rbf(cost = tune(), rbf_sigma = tune(), margin = tune()) %>%
  set_engine("kernlab") %>%
  set_mode("regression")

svm_tuning_grid <- grid_max_entropy(parameters(svm_rbf_model), size = 25)

svm_wkflow <- workflow() %>%
  add_recipe(svm_recipe) %>%
  add_model(svm_rbf_model)

svm_tuned <- svm_wkflow %>%
  tune_grid(grid = svm_tuning_grid, resamples = nfl_folds)

svm_tune_wkflow <- finalize_workflow(
    svm_wkflow,
    select_best(svm_tuned, "rmse")
  )

svm_cv_fit <- svm_tune_wkflow %>%
  fit_resamples(resamples = nfl_folds)

svm_metrics <- collect_metrics(svm_cv_fit)
```

```{r, eval = F}
nn_model <- mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>%
  set_engine("nnet") %>%
  set_mode("regression")

nn_tuning_grid <- grid_max_entropy(parameters(nn_model), size = 25)

nn_wkflow <- workflow() %>%
  add_recipe(svm_recipe) %>%
  add_model(nn_model)

nn_tuned <- nn_wkflow %>%
  tune_grid(grid = nn_tuning_grid, resamples = nfl_folds)

nn_tune_wkflow <- finalize_workflow(
    nn_wkflow,
    select_best(nn_tuned, "rmse")
  )

nn_cv_fit <- nn_tune_wkflow %>%
  fit_resamples(resamples = nfl_folds)

nn_metrics <- collect_metrics(nn_cv_fit)
```

```{r, eval = F}
rf_recipe <- all_data %>% recipe(fantasy_points ~ .) %>%
  update_role(gsis_id, full_name, new_role = "id") %>%
  update_role(headshot_url, new_role = "graphics") %>%
  update_role(fantasy_points_ppr, new_role = "comparison") %>%
  step_corr(all_numeric_predictors(), threshold = 0.9) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_nzv(all_predictors())

rf_model <- rand_forest(
    mtry = tune(),
    trees = tune(),
    min_n = tune()
  ) %>%
  set_engine("ranger") %>%
  set_mode("regression")

rf_param <- 
   rf_model %>% 
   parameters() %>% 
   finalize(x = all_data %>% select(-fantasy_points))

rf_tuning_grid <- grid_max_entropy(rf_param, size = 50)

rf_wkflow <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_model)

rf_tuned <- rf_wkflow %>%
  tune_grid(grid = rf_tuning_grid, resamples = nfl_folds)

rf_tune_wkflow <- finalize_workflow(
    rf_wkflow,
    select_best(rf_tuned, "rmse")
  )

rf_cv_fit <- rf_tune_wkflow %>%
  fit_resamples(resamples = nfl_folds)

rf_metrics <- collect_metrics(rf_cv_fit)
```

```{r, eval = F}
elastic_model <- linear_reg(penalty = tune(), mixture = tune()) %>%
  set_mode("regression") %>%
  set_engine("glmnet")

elastic_tuning_grid <- grid_max_entropy(parameters(elastic_model), size = 50)

elastic_wkflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(elastic_model)

elastic_tuned <- elastic_wkflow %>%
  tune_grid(grid = elastic_tuning_grid, resamples = nfl_folds)

elastic_tune_wkflow <- finalize_workflow(
    elastic_wkflow,
    select_best(elastic_tuned, "rmse")
  )

elastic_cv_fit <- elastic_tune_wkflow %>%
  fit_resamples(resamples = nfl_folds)

elastic_metrics <- collect_metrics(elastic_cv_fit)
```

```{r, eval = F}
set.seed(321)
nfl_split <- initial_split(all_data, prop = 0.8, strata = position)
nfl_train <- training(nfl_split)
nfl_test <- testing(nfl_split)

xgb_final_fit <- xgb_tune_wkflow %>% fit(data = nfl_train)
xgb_final_test <- augment(xgb_final_fit, new_data = nfl_test)

svm_final_fit <- svm_tune_wkflow %>% fit(data = nfl_train)
svm_final_test <- augment(svm_final_fit, new_data = nfl_test)

nn_final_fit <- nn_tune_wkflow %>% fit(data = nfl_train)
nn_final_test <- augment(nn_final_fit, new_data = nfl_test)

rf_final_fit <- rf_tune_wkflow %>% fit(data = nfl_train)
rf_final_test <- augment(rf_final_fit, new_data = nfl_test)

elastic_final_fit <- elastic_tune_wkflow %>% fit(data = nfl_train)
elastic_final_test <- augment(elastic_final_fit, new_data = nfl_test)
```

```{r, eval = F}
cv_metrics_table <- tibble("Model"="Stochastic Gradient Boosting", "RMSE"= xgb_metrics$mean[1], "R^2" = xgb_metrics$mean[2]) %>%
  add_row(
      "Model"="Radial SVM",
      "RMSE"= svm_metrics$mean[1],
      "R^2" =svm_metrics$mean[2]
    ) %>% add_row(
      "Model"="Neural Net",
      "RMSE"= nn_metrics$mean[1],
      "R^2" =nn_metrics$mean[2]
    ) %>% add_row(
      "Model"="Random Forest",
      "RMSE"= rf_metrics$mean[1],
      "R^2" =rf_metrics$mean[2]
    ) %>% add_row(
      "Model"="Elastic Net",
      "RMSE"= elastic_metrics$mean[1],
      "R^2" = elastic_metrics$mean[2]
    )
```

```{r, eval = F}
project_metrics <- metric_set(rmse, rsq)
xgb_final_metrics <- project_metrics(xgb_final_test, truth = fantasy_points, estimate = .pred)
svm_final_metrics <- project_metrics(svm_final_test, truth = fantasy_points, estimate = .pred)
nn_final_metrics <- project_metrics(nn_final_test, truth = fantasy_points, estimate = .pred)
rf_final_metrics <- project_metrics(rf_final_test, truth = fantasy_points, estimate = .pred)
elastic_final_metrics <- project_metrics(elastic_final_test, truth = fantasy_points, estimate = .pred)

final_metrics_table <- tibble("Model"="Stochastic Gradient Boosting", "RMSE"= xgb_final_metrics$.estimate[1], "R^2" = xgb_final_metrics$.estimate[2]) %>%
  add_row(
      "Model"="Radial SVM",
      "RMSE"= svm_final_metrics$.estimate[1],
      "R^2" =svm_final_metrics$.estimate[2]
    ) %>% add_row(
      "Model"="Neural Net",
      "RMSE"= nn_final_metrics$.estimate[1],
      "R^2" =nn_final_metrics$.estimate[2]
    ) %>% add_row(
      "Model"="Random Forest",
      "RMSE"= rf_final_metrics$.estimate[1],
      "R^2" =rf_final_metrics$.estimate[2]
    ) %>% add_row(
      "Model"="Elastic Net",
      "RMSE"= elastic_final_metrics$.estimate[1],
      "R^2" = elastic_final_metrics$.estimate[2]
    )
```

```{r, eval = F}
xgb_21_fit <- xgb_tune_wkflow %>% fit(data = all_data)
xgb_21_test <- augment(xgb_final_fit, new_data = all_data_2020)

svm_21_fit <- svm_tune_wkflow %>% fit(data = all_data)
svm_21_test <- augment(svm_final_fit, new_data = all_data_2020)

nn_21_fit <- nn_tune_wkflow %>% fit(data = all_data)
nn_21_test <- augment(nn_final_fit, new_data = all_data_2020)

rf_21_fit <- rf_tune_wkflow %>% fit(data = all_data)
rf_21_test <- augment(rf_final_fit, new_data = all_data_2020)

elastic_21_fit <- elastic_tune_wkflow %>% fit(data = all_data)
elastic_21_test <- augment(elastic_final_fit, new_data = all_data_2020)
```

```{r, eval = F}
xgb_21_metrics <- project_metrics(xgb_21_test, truth = fantasy_points, estimate = .pred)
svm_21_metrics <- project_metrics(svm_21_test, truth = fantasy_points, estimate = .pred)
nn_21_metrics <- project_metrics(nn_21_test, truth = fantasy_points, estimate = .pred)
rf_21_metrics <- project_metrics(rf_21_test, truth = fantasy_points, estimate = .pred)
elastic_21_metrics <- project_metrics(elastic_21_test, truth = fantasy_points, estimate = .pred)

final_metrics_table_21 <- tibble("Model"="Stochastic Gradient Boosting", "RMSE"= xgb_21_metrics$.estimate[1], "R^2" = xgb_21_metrics$.estimate[2]) %>%
  add_row(
      "Model"="Radial SVM",
      "RMSE"= svm_21_metrics$.estimate[1],
      "R^2" =svm_21_metrics$.estimate[2]
    ) %>% add_row(
      "Model"="Neural Net",
      "RMSE"= nn_21_metrics$.estimate[1],
      "R^2" =nn_21_metrics$.estimate[2]
    ) %>% add_row(
      "Model"="Random Forest",
      "RMSE"= rf_21_metrics$.estimate[1],
      "R^2" =rf_21_metrics$.estimate[2]
    ) %>% add_row(
      "Model"="Elastic Net",
      "RMSE"= elastic_21_metrics$.estimate[1],
      "R^2" = elastic_21_metrics$.estimate[2]
    )
```

## Introduction

In this paper, I will be analyzing NFL data in order to predict the amount of fantasy football points that a player will score in their upcoming games. This question originated from a project that I was completing for my software development class. My team wanted to build a football analytics app to help fantasy football players make data-driven decisions when building their rosters and choosing who to play each week (check out our app [here](https://github.com/jakesnyder7/pyball)). After working with the NFL data to create our analytics app, I became curious about how fantasy football performance predictions are made. I realized that with the comprehensive data I had gathered, I could apply machine learning techniques to derive my own model for predicting fantasy football points. Predictions for player performance are integral to helping fantasy football players make decisions, and accurate predictions can lead to a distinct advantage in winning fantasy football games.

For my research, I aim to answer the following questions: **How many fantasy points will this player score in their next game?** **Which player will score the most fantasy points in the next game?**

In order to answer my research questions, I use data from `nflverse`, a package created for `R`. The `nflverse` collects weekly player performance data in the forms of statistics and advanced metrics as well as static player data such as NFL combine performance. I combine all of the available data into one data frame to perform modeling. I am focusing specifically on data from the 2021-2022 NFL season.

Fantasy football points are calculated as a linear combination of various player performance statistics. Different leagues use slightly different calculations, but I use [standard fantasy points](https://www.espn.com/fantasy/football/ffl/story?page=fflrulesstandardscoring) for the player scoring system. My outcome, `fantasy_points`, indicates the number of standard fantasy points that a player scored each week.

In order to create a predictive model that can be used to estimate fantasy points before a game is played, I used the players' performance from the previous week and season totals of statistics through the prior week as predictors in the model. With these data modifications, the model can be used on real data in future seasons to estimate performance before a game has even been played.

## Exploratory Data Analysis

```{r}
all_data %>%
  group_by(full_name) %>%
  summarize(avg = mean(fantasy_points)) %>%
  ggplot(aes(x = avg)) +
  geom_histogram(fill = 'cornflowerblue') +
  labs(
      x = 'Average Fantasy Points',
      y = 'Number of Players',
      title = 'Average Fantasy Points Per Player',
      caption = 'The distribution of average fantasy points scored per player throughout the 2021-2022 NFL season.',
      tag = "Figure 1"
    )
```

```{r}
player_summary <- all_data %>% 
  mutate(mean = mean(fantasy_points)) %>%
  group_by(position) %>%
  summarize(
      fantasy_points_avg = mean(fantasy_points),
      distance_mean = fantasy_points_avg - mean,
      sd = sd(fantasy_points, na.rm = T),
      scoring_players = n_distinct(gsis_id),
    ) %>%
  distinct() %>%
  ungroup() %>%
  arrange(-scoring_players) %>%
  slice_head(n = 5)

team_summary <- all_data %>%
  group_by(team) %>%
  summarize(
      fantasy_points_avg = mean(fantasy_points),
      sd = sd(fantasy_points, na.rm = T),
      scoring_players = n_distinct(gsis_id)
    ) %>%
  arrange(-fantasy_points_avg) %>%
  slice_head(n = 10)
```

Fantasy football points are scored as a function of real statistics from performance in NFL games. Since much of the scoring is related to scoring touchdowns and gaining yards in NFL games, defensive players play a very small role in fantasy football. The majority of players score few points per game. In **Figure 1**, we see that the distribution of average fantasy points scored per player is right skewed. This indicates that while a few star players typically score highly in fantasy football, most players tend to score very few points each game. Note that players can score negative fantasy points as well.

```{r}
player_summary %>% kable(
    caption = "Table 1: A summary of the dataset stratified by player position.",
    col.names = c("Position", "Avg Fantasy Points", "Distance from Overall Avg Fantasy Points", "Standard Deviation", "Scoring Players")
  ) %>% kable_classic(full_width = F)
```

**Table 1** shows how the average fantasy points scored per player is largely tied to the player's position on the field. We observe that quarterbacks, the highest scoring position, score on average 7.41 points more than the average for all positions. Wide receivers and running backs also tend to be high scoring positions. This is tied to the fact that these positions are very involved in gaining more yards on the field and scoring points. Notice that these high scoring positions tend to have very high standard deviations. Every position has some outstanding players who score very highly along with some poor performers, resulting in large spreads. The positions with the most players tend to have the greatest standard deviations. This also points to the fact that position can not explain all of the variability in fantasy points scored.

```{r}
team_summary %>% kable(
    caption = "Table 2: A summary of the dataset stratified by team.",
    col.names = c("Team", "Avg Fantasy Points", "Standard Deviation", "Scoring Players")
  ) %>% kable_classic(full_width = F)
```

**Table 2** shows that another explanation of the variability in fantasy points is the team that a player is associated with. Notice that the best performing teams in terms of fantasy points align with the best performing teams in the NFL season. We see that the Superbowl champions, the LA Rams (`LA`), score the highest in terms of average fantasy points. Their Superbowl competitors, the Cincinnati Bengals (`CIN`), also rank highly in this statistic. This indicates that a player on a high performing team is more likely to score more fantasy points. Notice that the standard deviation is pretty consistent for all teams, showing that the amount of variance explained by `team` is more predictable.

```{r}
all_data %>%
  ggplot(aes(x = fantasy_points)) +
  geom_histogram(aes(color = recent_team, fill = recent_team)) +
  facet_wrap(~recent_team) +
  scale_color_nfl(type = 'secondary') +
  scale_fill_nfl() +
  theme(legend.position = 'none') +
  labs(
      x = 'Fantasy Points',
      y = 'Count',
      title = 'Distribution of Fantasy Points by Team',
      caption = 'The distribution of fantasy points scored by throughout the season on each NFL team.',
      tag = 'Figure 2'
    )
```

**Figure 2** further demonstrates the influence of team on fantasy points scored. High performing teams like `LA` and `CIN` have flatter, less skewed distributions, showing how their players more consistently score highly in fantasy points. In contrast, teams with poor performance like the New York Giants, `NYG`, and the Jacksonville Jaguars, `JAX`, have highly skewed distributions with most values between 0 and 10. This demonstrates that good teams tend to have more players who score highly in fantasy points, while bad teams tend to have few high-scoring fantasy players.

## Methods

In order to predict fantasy points, I compared the results of 5 different machine learning models. I began with a stochastic gradient boosting model which I expected to be the best performer. I chose the stochastic gradient boosting model because it does not require imputation. Since different player positions earn different statistics, there is a lot of missing data in my data table. For example, a quarterback has no data for receptions or field goals scored. The decision tree model handles missing data well, so I expected the best performance.

Next, I used a few models that did require imputation, as most models do. For imputation, I wanted to use k-nearest neighbors, but it increased my computation times by days, and my limited computing power was not sufficient. Instead, I imputed numerical data using the median and nominal data using the mode. Both of these choices have limitations, but they were the most readily available in terms of computational time.

I used a radial support vector machine because these tend to perform very highly on a wide variety of types of data sets. I chose a radial kernel for my support vector machine because I knew that my data was not close to linear or polynomial. I also used a neural net because it is a similarly high performing model. I used the random forest model as well because I suspected that decision trees would perform highly with my data. Finally, I used an elastic net model to provide a comparison using a type of linear regression.

For all 5 models, I used cross-validation and tuning in order to maximize the performance of the models. The tuning parameters were chosen using a maximum entropy grid search. The best parameters were chosen as the ones that resulted in the lowest root mean square error (`RMSE`).

## Results

In order to test the performance of my models, I calculated the `RMSE` and `R^2` at three different points. First, I calculated the average `RMSE` and `R^2` from the results across the folds made with cross-validation. Next, I split the data into a test set and a training set, I trained the data with the training set, and I calculated the metrics with the test set. Finally, and most consequentially, I trained the models with the data from the 2021-2022 NFL season, and I tested my models using the data from the 2020-2021 NFL season. These results are the most important as they show how the model predicts on an entirely novel data set. When I reference my results, I will refer to the results from testing my model with the 2020-2021 season data.

```{r}
cv_metrics_table %>%
  bind_cols(
      final_metrics_table %>% select(RMSE, `R^2`)
    ) %>%
  bind_cols(
      final_metrics_table_21 %>% select(RMSE, `R^2`)
    ) %>%
  kable(
      col.names = c("Model", "RMSE", "R^2", "RMSE", "R^2", "RMSE", "R^2"),
      digits = 2,
      caption = "Table 3: Model performance measured after cross-validation, testing on split data, and testing on data from the 2020-2021 NFL season."
    ) %>%
  kable_classic(full_width = F) %>%
  add_header_above(c(" " = 1, "CV" = 2, "Split" = 2, "20-21 Data" = 2)) %>% 
  column_spec(6, bold = T) %>%
  column_spec(7, bold = T)
```

We see from **Table 3** that the stochastic gradient boosting model is clearly the best performer. In all test cases, it has both the lowest `RMSE` and highest `R^2`. When tested against the 2020-2021 NFL data, it results in a `RMSE` of 5.15 and an `R^2` of 0.51. The high performance of the stochastic gradient boosting model is likely due to both the superiority of the decision tree model and the fact that I did not need to impute data to use this model. The next best performer for all test cases is the random forest model, with an `RMSE` of 5.34 and `R^2` of 0.47. This again indicates the superiority of decision tree models for the data set that I am using. The worst performing model in all cases is the elastic net, resulting in an `RMSE` of 6.81 and a meager `R^2` of 0.14. The poor performance of the elastic net was expected due to the need to impute a large amount of data and the non-linear nature of the data.

Overall, we see that even the best models can only explain up to about 51% of the variance. The lowest `RMSE` we see is 5.15, which is still pretty high in the world of fantasy football where 5 points means the difference between a mediocre performance and an amazing one.

```{r}
xgb_21_test %>% ggplot() +
  geom_jitter(aes(x = fantasy_points, y = .pred), alpha = 0.2) + geom_abline(intercept = 0, slope = 1, color="red") + labs(
      x = 'Observed Fantasy Points',
      y = 'Predicted Fantasy Points (XGBoost)',
      title = 'Observed vs. Predicted Fantasy Points In XGBoost',
      tag = "Figure 3",
      caption="Observed fantasy points vs. predicted fantasy points in 2020-2021 NFL data using the stochastic gradient boosting model."
  )
```

From **Figure 3**, we see that the model tends to underpredict on outlier games were players score very highly. However, the model tends to slightly overpredict on games were players have very low fantasy scores. Generally, the model is pretty balanced in its predictions.

## Discussion

Through modeling, I found that the best performing model is stochastic gradient boosting. The model explains about 51% of the variance in fantasy points scored, and has an `RMSE` of 5.15.

The results of this study are limited due largely to limited computational power. Ideally, I would use a better method such as k-nearest neighbors or a decision tree for imputing missing data. I suspect that with better imputation, the radial support vector machine and the neural network models would perform comparably with the stochastic gradient boosting. Another limitation was the size of the tuning grids and the amount of folds in the cross validation. These were limited due to computational time in this study. Larger tuning grids for selecting the parameters for each model would likely refine the models and result in better predictive power.

For future research, a model would work well if it was tuned with all NFL data since the creation of Fantasy Football. This data is readily accessible, and it would help create the best model for predicting future fantasy football scores. While training this model would take a lot of computational power, more training data leads to better predictive power, so the model would be more prepared to make accurate fantasy football predictions. One future area of research is predicting the performance of rookies before the NFL season even begins. A different data set with collegiate data would be required to predict the fantasy points of rookies before they step foot in an NFL game.
